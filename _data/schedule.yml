- Title: Breakfast 
  Time: 08:15M - 08:20AM
  Whole_line: true

- Title: Opening Speech
  Time: 08:15AM - 08:20AM
  Whole_line: true  

- Title: Deploying efficient translation at every level of the stack (KeyNote Talk)
  Time: 08:20AM - 08:45AM
  Presenter: Kenneth Heafield
  Is_paper: false
  Whole_line: false
  Bio: Kenneth Heafield is the founder of Efficient Translation Limited and left the University of Edinburgh last week, where he was an Associate Professor.  He trained a large language model on a trillion tokens in 2013 before it was cool.  Then he ran EU projects ParaCrawl to gather data from the web, Bergamot to make fast translation for browsers, and HPLT to make language models large again.
  Abstract: Practical efficient neural networks combine several optimizations ranging from assembly code to network structure. Yet most papers about optimization start with an unoptimized baseline, omitting comparison even with simple methods like using a smaller network. Shared tasks force a different mentality, where each idea has to prove its worth against a highly optimized baseline. This informs our work on fast and small machine translation with latency under 20 ms for an average sentence. The models are now deployed in Firefox.

- Title: Simple and efficient self-training approaches for speech recognition (KeyNote Talk)
  Time: 08:45AM - 09:30AM
  Presenter: Samy Bengio <br> Tatiana Likhomanenko
  Is_paper: false
  Whole_line: false
  Bio: <b>Samy Bengio</b> is a senior director of machine learning research at Apple since 2021. Before that, he was a distinguished scientist at Google Research since 2007 where he was heading part of the Google Brain team, and at IDIAP in the early 2000s where he co-wrote the well-known open-source Torch machine learning library. His research interests span many areas of machine learning such as deep architectures, representation learning, vision and language processing and more recently, reasoning. He is action editor of the Journal of Machine Learning Research and on the board of the NeurIPS foundation. He was on the editorial board of the Machine Learning Journal, has been program chair (2017) and general chair (2018) of NeurIPS, program chair of ICLR (2015, 2016), general chair of BayLearn (2012-2015), MLMI (2004-2006), as well as NNSP (2002), and on the program committee of several international conferences such as NeurIPS, ICML, ICLR, ECML and IJCAI. More details can be found at http://bengio.abracadoudou.com. <br> <br> <b>Tatiana</b> is a research scientist at the machine learning research team at Apple. Prior to Apple, she was an AI resident and later a postdoctoral research scientist in the speech recognition team, Facebook AI Research. Back in the day, Tatiana received a Ph.D. in mixed type partial differential equations from Moscow State University. For 4 years she worked on applications of machine learning to high energy physics as a researcher in the joint lab at Yandex and CERN, and later at the startup NTechLab, a leader in face recognition. The main focus of her recent research is transformers training and generalization, efficient speech recognition with less supervision and private federated learning. 
  Abstract: Self-training, or pseudo-labeling (PL), algorithms have recently emerged as a powerful strategy for semi-supervised learning in speech recognition in the era of transformers and large scale data. In this talk, we will walk you from the first successful pseudo-labeling algorithms based on teacher-student training, that alternates between training a model and generating pseudo-labels (PLs) with it, to continuous pseudo-labeling algorithms, where PLs are generated in end-to-end manner as training proceeds, improving training speed and the accuracy of the final model. We will discuss different aspects of PL algorithms to make it simple and resource efficient and overall what are the key components of such huge success :what exactly the model learns, how training dynamics changes, how speaker diversity and amount of hours affect training, and how training depends on the language models. Finally, we will show how pseudo-labeling can be used to train a model on a source language with labeled data and to fine-tune it on a target language with only unlabeled data.
  
  
- Title: [Paper-Oral 1] Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL 
  Time: 09:30AM - 09:36AM
  Presenter: Hao Sun · Alihan Hüyük · Mihaela van der Schaar
  Is_paper: true
  Whole_line: false
  Authors: Hao Sun · Alihan Hüyük · Mihaela van der Schaar
  Abstract: In this study, we aim to enhance the arithmetic reasoning ability of Large Language Models (LLMs) through zero-shot prompt optimization. We identify a previously overlooked objective of query dependency in such optimization and elucidate two ensuing challenges that impede the successful and economical design of prompt optimization techniques. We introduce Prompt-OIRL, which harnesses offline inverse reinforcement learning to draw insights from offline prompting demonstration data. Such data exists as by-products when diverse prompts are benchmarked on open-accessible datasets. With Prompt-OIRL, the query-dependent prompt optimization objective is achieved by first learning an offline reward model. This model can evaluate any query-prompt pairs without accessing LLMs. Subsequently, a best-of-N strategy is deployed to recommend the optimal prompt. Our experimental evaluations across various LLM scales and arithmetic reasoning datasets underscore both the efficacy and economic viability of the proposed approach.
- Title: [Paper-Oral 2] MultiPrompter:Cooperative Prompt Optimization with Multi-Agent Reinforcement Learning
  Time: 09:36AM - 09:42AM
  Presenter: TBDDong-Ki Kim · Sungryull Sohn · Lajanugen Logeswaran · Dongsub Shim · Honglak Lee
  Is_paper: true
  Whole_line: false
  Authors: Dong-Ki Kim · Sungryull Sohn · Lajanugen Logeswaran · Dongsub Shim · Honglak Lee
  Abstract: TBDRecently, there has been an increasing interest in automated prompt optimization based on reinforcement learning (RL). This approach offers important advantages, such as generating interpretable prompts and being compatible with black-box foundation models. However, the substantial prompt space size poses challenges for RL-based methods, often leading to suboptimal policy convergence. This paper introduces MultiPrompter, a new framework that views prompt optimization as a cooperative game between prompters who take turns composing a prompt together. Our cooperative prompt optimization effectively reduces the problem size and helps prompters learn optimal prompts. We test our method on the text-to-image task and demonstrate its ability to generate higher-quality images than baselines.
- Title: (Paper Oral Presentation) TBD
  Time: 09:50AM - 10:00AM
  Presenter: TBD
  Is_paper: true
  Whole_line: false
  Authors: TBD
  Abstract: TBD
  
- Title: Morning Break and <b>Poster Setup</b>
  Time: 10:00AM - 10:30AM
  Whole_line: true


- Title: (KeyNote Talk) TBD
  Time: 10:30AM - 11:00AM
  Presenter: Luke Zettelmoyer
  Is_paper: false
  Whole_line: false
  Bio: TBD
  Abstract: TBD
- Title: (KeyNote Talk) TBD
  Time: 11:00AM - 11:30AM
  Presenter: Sarath Chandar
  Is_paper: false
  Whole_line: false
  Bio: TBD
  Abstract: TBD
  

- Title: (Paper Oral Presentation) TBD
  Time: 11:30AM - 11:40AM
  Presenter: TBD
  Is_paper: true
  Whole_line: false
  Authors: TBD
  Abstract: TBD
- Title: (Paper Oral Presentation) TBD
  Time: 11:40AM - 11:50AM
  Presenter: TBD
  Is_paper: true
  Whole_line: false
  Authors: TBD
  Abstract: TBD
- Title: (Paper Oral Presentation) TBD
  Time: 11:50AM - 12:00PM
  Presenter: TBD
  Is_paper: true
  Whole_line: false
  Authors: TBD
  Abstract: TBD

- Title: Lunch Break
  Time: 12:00PM - 12:45PM
  Whole_line: true
 
- Title: <b>Poster Session I</b>
  Time: 12:45PM - 01:45PM
  Whole_line: true
  
- Title: (KeyNote Talk) TBD
  Time: 01:45PM - 02:15PM
  Presenter: Ali Madani
  Is_paper: false
  Whole_line: false
  Bio: TBD
  Abstract: TBD  
  
- Title: Interactive Industrial Panel
  Time: 02:15PM - 03:00PM
  Presenter: <ul><li>Nazneen Rajan</li><li>Minjia Zhang</li><li>Tanya Roosta</li><li>Tim Dettmers</li></ul>
  Is_paper: false
  Whole_line: false

- Title: Afternoon Break and <b>Poster Session II</b>
  Time: 03:00PM - 03:30PM
  Whole_line: true

- Title: (KeyNote Talk) TBD
  Time: 03:30PM-04:00PM
  Presenter: Tara Sainath
  Is_paper: false
  Whole_line: false
  Bio: TBD
  Abstract: TBD  
  
  
- Title: (KeyNote Talk) TBD
  Time: 04:00PM-04:30PM
  Presenter: Haoli Bai
  Is_paper: false
  Whole_line: false
  Bio: TBD
  Abstract: TBD  
  
- Title: (KeyNote Talk) TBD
  Time: 04:30PM-05:00PM
  Presenter: Kenneth Heafield
  Is_paper: false
  Whole_line: false
  Bio: TBD
  Abstract: TBD  


- Title: Best Paper and Poster Award & Closing
  Time: 05:00PM-05:10PM
  Whole_line: true
